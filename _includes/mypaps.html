<table>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="icml2021">1</a>]
</td>
<td class="bibtexitem">
Vincent Plassier, Maxime Vono, Alain Durmus, Eric Moulines:
<I> DG-LMC: A Turn-key and Scalable Synchronous Distributed MCMC Algorithm via Langevin Monte Carlo within Gibbs. </I>
<br> 
<strong> International Conference on Machine Learning (ICML) </strong> (2021).
[&nbsp; <a href="https://arxiv.org/abs/2106.06300">ArXiv</a>&nbsp;]
</td>
</tr>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="qlsd">2</a>]
</td>
<td class="bibtexitem">
Vincent Plassier, Maxime Vono, Alain Durmus, Aymeric Dieuleveut, Eric Moulines:
<I> QLSD: Quantised Langevin Stochastic Dynamics for Bayesian Federated Learning. </I>
<br> 
<strong> International Conference on Artificial Intelligence and Statistics (AISTATS) </strong> (2022).
[&nbsp;<a href="https://proceedings.mlr.press/v151/vono22a">Proceedings</a>&nbsp;]
</td>
</tr>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="mia">3</a>]
</td>
<td class="bibtexitem">
Hamid Jalalzai*, Elie Kadoche*, Rémi Leluc* and Vincent Plassier*:
<I> Membership Inference Attacks via Adversarial Examples. </I>
<br> 
<strong> NeurIPS Workshop on Trustworthy and Socially Responsible Machine Learning </strong> (2022).
[&nbsp;<a href="http://arxiv.org/abs/2207.13572">ArXiv</a>&nbsp;]
</td>
</tr>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="mia">4</a>]
</td>
<td class="bibtexitem">
Vincent Plassier, Alain Durmus, Eric Moulines:
<I> Federated averaging Langevin Dynamics: Toward a unified theory and new algorithms. </I>
<br> 
<strong> International Conference on Artificial Intelligence and Statistics (AISTATS) </strong> (2022).
[&nbsp;<a href="https://proceedings.mlr.press/v206/plassier23a/plassier23a.pdf">Proceedings</a>&nbsp;]
</td>
</tr>
  
<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="ihp">5</a>]
</td>
<td class="bibtexitem">
Vincent Plassier, François Portier and Johan Segers:
<I> Risk bounds when learning infinitely many response functions by ordinary linear regression. </I>
<br> 
<strong> Annales de l'Institut Henri Poincaré (AIHP) </strong> (2023).
[&nbsp; <a href="https://arxiv.org/abs/2006.09223">ArXiv</a>&nbsp;]
</td>
</tr>  

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="mia">6</a>]
</td>
<td class="bibtexitem">
Vincent Plassier, Mehdi Makni, Aleksandr Rubashevskii, Eric Moulines and Maxim Panov:
<I> Conformal Prediction for Federated Uncertainty Quantification Under Label Shift. </I>
<br> 
<strong> In International Conference on Machine Learning </strong> (2023).
[&nbsp;<a href="https://arxiv.org/abs/2306.05131">ArXiv</a>&nbsp;]
</td>
</tr>

<tr valign="top">
    <td align="right" class="bibtexnumber">
    [<a name="mia">7</a>]
    </td>
    <td class="bibtexitem">
        Vincent Plassier, Nikita Kotelevskii, Aleksandr Rubashevskii, Fedor Noskov, Maksim Velikanov, Alexander Fishkov, Samuel Horvath, Martin Takac, Eric Moulines and Maxim Panov:
    <I> Efficient Conformal Prediction under Data Heterogeneity. </I>
    <br> 
    <strong> International Conference on Artificial Intelligence and Statistics (AISTATS) </strong> (2024).
    [&nbsp;<a href="https://arxiv.org/abs/2312.15799">ArXiv</a>&nbsp;]
    </td>
    </tr>
        
</table>
